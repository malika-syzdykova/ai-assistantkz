import streamlit as st
from langchain_community.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import CharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.chains.qa_with_sources.retrieval import RetrievalQAWithSourcesChain
from langchain_openai import ChatOpenAI
from PyPDF2 import PdfReader
from dotenv import load_dotenv
import os

load_dotenv()
openai_key = os.getenv("OPENAI_API_KEY")

st.set_page_config(page_title="AI –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏—è –†–ö")
st.title("üìú AI Assistant –ø–æ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –†–ö")

uploaded_files = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ PDF-–¥–æ–∫—É–º–µ–Ω—Ç—ã", accept_multiple_files=True)

if uploaded_files:
    all_text = ""
    for file in uploaded_files:
        reader = PdfReader(file)
        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                all_text += page_text

    # –£–º–µ–Ω—å—à–µ–Ω–Ω—ã–µ —á–∞–Ω–∫–∏
    text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)
    texts = text_splitter.split_text(all_text)

    embeddings = OpenAIEmbeddings(openai_api_key=openai_key)
    db = Chroma.from_texts(texts, embedding=embeddings, persist_directory="db")
    retriever = db.as_retriever(search_kwargs={"k": 3})

    llm = ChatOpenAI(openai_api_key=openai_key, model="gpt-4-1106-preview")


    qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="map_reduce",  # ‚Üê —Ç—É—Ç –∫–ª—é—á–µ–≤–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ
    retriever=retriever,
    return_source_documents=False
)
    query = st.text_input("–ó–∞–¥–∞–π –≤–æ–ø—Ä–æ—Å:")
    if query:
        try:
            result = qa_chain.run(query)
            st.write("–û—Ç–≤–µ—Ç:", result)
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞: {str(e)}")
